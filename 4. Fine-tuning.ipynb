{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d113dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM, PeftModel\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159d3c8",
   "metadata": {},
   "source": [
    "- 데이터셋 분할(8:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27f70ddf56343969447acf668805353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3605bd4b5bed48df9267e0132041c14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2648a9a282d3400fb19c8adc08624fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터의 type 분포:\n",
      "no_answer: 328\n",
      "mrc_question: 662\n",
      "\n",
      "전체 데이터 분할 결과: Train 793개, Test 197개\n",
      "\n",
      "학습 데이터의 type 분포:\n",
      "no_answer: 263\n",
      "mrc_question: 530\n",
      "\n",
      "테스트 데이터의 type 분포:\n",
      "no_answer: 65\n",
      "mrc_question: 132\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"eddyfox8812/otc-mrc-ko-rag-dataset\", split=\"train\")\n",
    "\n",
    "system_message = \"\"\"당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
    "\n",
    "다음의 지시사항을 따르십시오.\n",
    "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
    "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
    "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
    "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
    "5. 문서에는 반드시 약물의 이름이 기재되어 있습니다. 사용자가 질문하는 약물만을 정확히 찾아 해당 문서만을 인용하여 답변하십시오.\n",
    "6. 반드시 사용자가 질문한 약물에 관한 문서로만 답변해야 합니다. 약물이 다른 문서를 절대로 인용하지 마십시오\n",
    "\n",
    "검색 결과:\n",
    "-----\n",
    "{search_result}\"\"\"\n",
    "\n",
    "print(\"원본 데이터의 type 분포:\")\n",
    "for type_name in set(dataset['type']):\n",
    "    print(f\"{type_name}: {dataset['type'].count(type_name)}\")\n",
    "\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for type_name in set(dataset['type']):\n",
    "    curr_type_data = [i for i in range(len(dataset)) if dataset[i]['type'] == type_name]\n",
    "     \n",
    "    test_size = int(len(curr_type_data) * test_ratio)\n",
    "    \n",
    "    test_data.extend(curr_type_data[:test_size])\n",
    "    train_data.extend(curr_type_data[test_size:])\n",
    "\n",
    "def format_data(sample):\n",
    "    search_result = \"\\n-----\\n\".join([f\"문서{idx + 1}: {result}\" for idx, result in enumerate(sample[\"search_result\"])])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message.format(search_result=search_result),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sample[\"question\"],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": sample[\"answer\"]\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "train_dataset = [format_data(dataset[i]) for i in train_data]\n",
    "test_dataset = [format_data(dataset[i]) for i in test_data]\n",
    "\n",
    "print(f\"\\n전체 데이터 분할 결과: Train {len(train_dataset)}개, Test {len(test_dataset)}개\")\n",
    "\n",
    "print(\"\\n학습 데이터의 type 분포:\")\n",
    "for type_name in set(dataset['type']):\n",
    "    count = sum(1 for i in train_data if dataset[i]['type'] == type_name)\n",
    "    print(f\"{type_name}: {count}\")\n",
    "\n",
    "print(\"\\n테스트 데이터의 type 분포:\")\n",
    "for type_name in set(dataset['type']):\n",
    "    count = sum(1 for i in test_data if dataset[i]['type'] == type_name)\n",
    "    print(f\"{type_name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670e283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\\n\\n다음의 지시사항을 따르십시오.\\n1. 질문과 검색 결과를 바탕으로 답변하십시오.\\n2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\\n3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\\n4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\\n5. 문서에는 반드시 약물의 이름이 기재되어 있습니다. 사용자가 질문하는 약물만을 정확히 찾아 해당 문서만을 인용하여 답변하십시오.\\n6. 반드시 사용자가 질문한 약물에 관한 문서로만 답변해야 합니다. 약물이 다른 문서를 절대로 인용하지 마십시오\\n\\n검색 결과:\\n-----\\n문서1: 옵티노즈연질캡슐 :\\n\\n### 주의사항(1)\\n5. 다음과 같은 경우 이 약의 복용을 즉각 중지하고 의사, 치과의사, 약사와 상의할 것. 상담 시 가능한 한 이 첨\\n부문서를 소지할 것.\\n1) 이 약의 복용에 의해 다음의 증상이 나타난 경우\\n발진·발적(충혈되어 붉어짐), 가려움, 구역·구토, 식욕부진, 변비, 부종(부기), 배뇨(소변을 눔)곤란, 목마름\\n(지속적이거나 심한), 어지러움, 불안, 떨림, 불면\\n2) 이 약의 복용에 의해 드물게 아래의 중증(심한 증상) 증상이 나타난 경우\\n① 쇽(아나필락시)(과민성쇼크) : 복용후 바로 두드러기, 부종(부기), 가슴답답함 등과 함께 안색이 창백하\\n\\n① 쇽(아나필락시)(과민성쇼크) : 복용후 바로 두드러기, 부종(부기), 가슴답답함 등과 함께 안색이 창백하\\n고, 손발이 차고, 식은땀, 숨쉬기 곤란함 등이 나타날 수 있다.\\n② 피부점막안증후군(스티븐스-존슨증후군), 중독성표피괴사용해(리엘증후군) : 고열을 동반하고, 발진·발\\n적(충혈되어 붉어짐), 화상과 같이 물집이 생기는 등의 심한 증상이 전신피부, 입이나 눈점 막에 나타날 수 \\n있다.\\n③ 급성 전신성 발진성 농포증(AGEP)과 같은 중증 피부 이상반응이 나타날 수 있다.\\n④ 천식\\n⑤ 간기능장애 : 전신의 나른함, 황달(피부 또는 눈의 흰자위가 황색을 띄게 됨)등이 나타날 수 있다.\\n⑥ 간질성폐렴 : 기침을 동반하고, 숨이 차고, 호흡곤란, 발열 등이 나타난다.\\n⑦ 슈도에페드린 성분과 관련하여 허혈성 대장염의 증상(급격한 복통, 직장 출혈 등)이 발현될 경우\\n⑧ 가역적 후뇌 병증 증후군 및 가역적 뇌혈관 수축 증후군: 갑작스러운 심한 두통, 번개 두통, 구역, 구 토, \\n혼돈, 발작, 시각 장애 등이 발현될 수 있다.\\n3) 5~6회 복용하여도 증상이 좋아지지 않을 경우\\n-----\\n문서2: 부광더모픽스겔(세르타코나졸질산염)(수입명:Dermofixgel) :\\n\\n### 주의사항(1)\\n5. 기타 이 약의 사용시 주의할 사항\\n1) 주성분의 농도와 투여방법(경로)을 고려할 때 약물중독이 일어나는 것은 불가능하나, 우발적으로 복용한 \\n경우에는 적절한 처치를 하여야 한다.\\n2) 치료 첫날 약한 일과성의 발진이 나타날 수 있으나 치료를 중단할 필요는 없다.\\n-----\\n문서3: 본스칼츄어블정 :\\n\\n### 주의사항(1)\\n4. 다음과 같은 경우 이 약의 복용을 즉각 중지하고 의사, 치과의사, 약사와 상의할 것. 상담 시 가능한 한 이 첨\\n부문서를 소지할 것.\\n1) 이 약의 투여에 의하여 다음의 증상이 있을 경우\\n- 구역, 구토, 설사, 변비, 저혈압, 얼굴달아오름, 심박동불규칙, 피부발진\\n2) 대량투여로 인해 구역, 구토 등의 위장증상, 고나트륨혈증, 울혈심부전, 부종(부기) 등의 증상이 나타날 \\n수 있다.\\n3) 장기투여에 의해 고칼슘혈증 및 결석증이 나타날 수 있다.\\n4) 항알도스테론제, 트리암테렌과 병용(함께 복용)투여시 고칼륨혈증을 일으킬 수 있으므로 주의할 것.\\n5) 우발적으로 과량복용 한 경우\\n6) 1개월 정도 복용하여도 증상의 개선이 없을 경우\\n-----\\n문서4: 디클로맥스겔(디클로페낙디에틸암모늄) :\\n\\n### 주의사항(1)\\n4. 다음과 같은 경우 이 약의 사용을 즉각 중지하고 의사, 치과의사, 약사와 상의할 것. 상담시 가능한 한 이 첨부\\n문서를 소지할 것.\\n1) 면역계 : 과민반응, 혈관신경성 부종이 매우 드물게 나타날 수 있다.\\n2) 호흡기계 : 천식이 매우 드물게 나타날 수 있다.\\n3) 피부 및 피하조직 : 이 약은 탈락성 피부염, 스티븐스-존슨 증후군 및 독성 표피괴사 같은 중대한 피부 이상\\n\\n3) 피부 및 피하조직 : 이 약은 탈락성 피부염, 스티븐스-존슨 증후군 및 독성 표피괴사 같은 중대한 피부 이상\\n반응을 일으킬 수 있으며, 이는 치명적일 수 있다. 이러한 중대한 이상반응은 경고 증상 없이 발생할 수 있다. \\n대부분의 경우 이러한 이상반응은 투여 초기 1개월 이내에 발생한다. 환자는 중대한 피부 발현 증상 및 증후\\n에 대해 알고 있어야 한다. 때때로, 발진, 습진, 홍반 및 피부염(접촉성피부염 포함)이 나타날 수 있으며, 드물\\n게 수포성 피부염이 나타날 수 있고, 매우 드물게 광과민반응, 농포성 발진이 나타날 수 있다.\\n4) 이 약을 넓은 부위에 장기간 사용할 경우 전신이상반응이 나타날 수 있다.\\n5) 갑자기 과용량을 사용하여 저혈압, 신부전, 경련, 위장관불쾌감 및 호흡기능억제등의 전신 이상반응이 나\\n타날 수 있다.\\n-----\\n문서5: 판텍큐노즈플러스연질캡슐 :\\n\\n### 주의사항(1)\\n5. 다음과 같은 경우 이 약의 복용을 즉각 중지하고 의사, 치과의사, 약사와 상의할 것. 상담 시 가능한 이 첨부문\\n서를 소지할 것.\\n1) 이 약의 복용에 의해 다음의 증상이 나타난 경우\\n발진ㆍ발적, 가려움, 구역ㆍ구토, 식욕부진, 변비, 부종, 배뇨곤란, 목마름(지속적이거나 심한), 어지러움, 불\\n안, 떨림, 불면\\n2) 이 약의 복용에 의해 드물게 아래의 중증 증상이 나타난 경우\\n① 쇽(아나필락시): 복용 후 바로 두드러기, 부종(부기), 가슴답답함 등과 함께 안색이 창백하고, 손발이 차\\n고, 식은땀, 숨쉬기 곤란함 등이 나타날 수 있다.\\n\\n② 피부점막안증후군(스티븐스-존슨증후군), 중독성표피괴사용해(리엘증후군): 고열을 동반하고, 발진ㆍ발\\n적, 화상과 같이 물집이 생기는 등의 심한 증상이 전신피부, 입이나 눈점막에 나타날 수 있다.\\n③ 급성 전신성 발진성 농포증(AGEP), 발열, 홍반, 다수의 작은 농포와 같은 중증 피부 이상반 응이 나타날 \\n수 있다.\\n④ 천식\\n⑤ 간기능장애 : 전신의 나른함, 황달(피부 또는 눈의 흰자위가 황색을 띄게 됨)등 이 나타날 수 있다.\\n⑥ 간질성폐렴: 기침을 동반하고, 숨이 차고, 호흡곤란, 발열 등이 나타난다.\\n⑦ 가역적 후뇌 병증 증후군 및 가역적 뇌혈관 수축 증후군: 갑작스러운 심한 두통, 번개 두통, 구역, 구토, 혼\\n돈, 발작, 시각 장애 등이 발현될 수 있다.\\n3) 5~6회 복용하여도 증상이 좋아지지 않을 경우'},\n",
       " {'role': 'user', 'content': '부광더모픽스겔을 우발적으로 복용하면 어떻게 해야 하나요?'},\n",
       " {'role': 'assistant',\n",
       "  'content': '부광더모픽스겔을 우발적으로 복용한 경우에는 약물중독이 일어나는 것은 불가능하다고 알려져 있으나, 적절한 처치를 해야 합니다. 따라서 우발적으로 복용한 경우에는 즉시 의료기관에 연락하여 지침을 받는 것이 중요합니다[[ref2]].'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset[345][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2eb5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))\n",
    "print(type(test_dataset))\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6797bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec17aaf8a14454ab0b66d2dc022ebcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/197 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset.save_to_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505df4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001cd7e8f4a24d7bbf76f83c0523567e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3223318e3de84d8db9471e6e1e7e297a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773b2d054f9e41879fb89fa910db3ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f8405d187942a5bc6e8226c08db499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce429c9e3797404f865258585ffc45f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf951c555734c5ba328ee60811f898c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3a1a06732b4318b29525fb6379b073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fcb47ea95a49339966139f157822b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c605f4a59a484b73954b659acf025bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f77e822d9b84611ae87aba6f16cb73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307417e480af4c4a8f4e31162e2606fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\" \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 문서에는 반드시 약물의 이름이 기재되어 있습니다. 사용자가 질문하는 약물만을 정확히 찾아 해당 문서만을 인용하여 답변하십시오.\n",
      "6. 반드시 사용자가 질문한 약물에 관한 문서로만 답변해야 합니다. 약물이 다른 문서를 절대로 인용하지 마십시오\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 복합마이녹실액5% :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 이 약은 인화성이 있으므로 화기를 피한다.\n",
      "2) 어린이의 손이 닿지 않는 곳에 보관한다.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용에 따른 사고 발생이나 의약품 품\n",
      "질저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관한다.\n",
      "-----\n",
      "문서2: 메디녹실액5%(미녹시딜) :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 이 약은 인화성이 있으므로 화기를 피한다.\n",
      "2) 어린이의 손이 닿지 않는 곳에 보관한다.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용에 따른 사고 발생이나 의약품 품\n",
      "질저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관한다.\n",
      "-----\n",
      "문서3: 카필러스액5%(미녹시딜) :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 이 약은 인화성이 있으므로 화기를 피한다.\n",
      "2) 어린이의 손이 닿지 않는 곳에 보관한다.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용에 따른 사고 발생이나 의약품 품\n",
      "질저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관한다.\n",
      "-----\n",
      "문서4: 외유내간연질캡슐(밀크시슬열매건조엑스) :\n",
      "\n",
      "### 주의사항(1)\n",
      "5. 저장상의 주의사항\n",
      "1) 어린이의 손이 닿지 않는 곳에 보관할 것.\n",
      "2) 직사광선을 피하고 될 수 있으면 습기가 적고 서늘한 곳에 밀전하여(뚜껑을 꼭 닫아) 보관할 것.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용(잘못 사용)에 의한 사고발생이나 \n",
      "의약품 품질 저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관할 것.\n",
      "-----\n",
      "문서5: 마그포스스피드액 :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 어린이의 손에 닿지 않는 곳에 보관할 것.\n",
      "2) 직사광선을 피하고 될 수 있는 한 습기가 적은 서늘한 곳에 (밀폐하여) 보관할 것.\n",
      "3) 오용(잘못 사용)을 막고 품질의 보존을 위하여 다른 용기에 바꾸어 넣지 말 것.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "복합마이녹실액5%와 다른 약물의 상호작용은 어떤 게 있어?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "검색 결과에는 복합마이녹실액5%와 다른 약물의 상호작용을 찾을 수 없습니다.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    train_dataset[0][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        r=8,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir=\"llama-3-8b-otc-rag-ko\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    bf16=True,\n",
    "    learning_rate=1e-4, \n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f45979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    for example in batch:\n",
    "        messages = example[\"messages\"]\n",
    "\n",
    "        prompt = \"<|begin_of_text|>\"\n",
    "        for msg in messages:\n",
    "            role = msg[\"role\"]\n",
    "            content = msg[\"content\"].strip()\n",
    "            prompt += f\"<|start_header_id|>{role}<|end_header_id|>\\n{content}<|eot_id|>\"\n",
    "\n",
    "        text = prompt.strip()\n",
    "\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_seq_length,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        labels = [-100] * len(input_ids)\n",
    "\n",
    "        assistant_header = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        assistant_tokens = tokenizer.encode(assistant_header, add_special_tokens=False)\n",
    "        eot_token = \"<|eot_id|>\"\n",
    "        eot_tokens = tokenizer.encode(eot_token, add_special_tokens=False)\n",
    "\n",
    "        i = 0\n",
    "        while i <= len(input_ids) - len(assistant_tokens):\n",
    "            if input_ids[i:i + len(assistant_tokens)] == assistant_tokens:\n",
    "                start = i + len(assistant_tokens)\n",
    "                end = start\n",
    "                while end <= len(input_ids) - len(eot_tokens):\n",
    "                    if input_ids[end:end + len(eot_tokens)] == eot_tokens:\n",
    "                        break\n",
    "                    end += 1\n",
    "                for j in range(start, end):\n",
    "                    labels[j] = input_ids[j]\n",
    "                for j in range(end, end + len(eot_tokens)):\n",
    "                    labels[j] = input_ids[j] \n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch[\"labels\"].append(labels)\n",
    "\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        pad_len = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        new_batch[\"input_ids\"][i].extend([tokenizer.pad_token_id] * pad_len)\n",
    "        new_batch[\"attention_mask\"][i].extend([0] * pad_len)\n",
    "        new_batch[\"labels\"][i].extend([-100] * pad_len)\n",
    "\n",
    "    for k in new_batch:\n",
    "        new_batch[k] = torch.tensor(new_batch[k])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리된 배치 데이터:\n",
      "입력 ID 형태: torch.Size([1, 981])\n",
      "어텐션 마스크 형태: torch.Size([1, 981])\n",
      "레이블 형태: torch.Size([1, 981])\n"
     ]
    }
   ],
   "source": [
    "max_seq_length=8192\n",
    "\n",
    "example = train_dataset[0]\n",
    "batch = collate_fn([example])\n",
    "\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35648354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 대한 정수 인코딩 결과:\n",
      "[128000, 128006, 9125, 128007, 198, 65895, 83628, 34804, 115036, 99901, 18918, 82818, 120378, 43139, 109760, 19954, 111964, 110513, 109670, 382, 13447, 49531, 21028, 67890, 30426, 115790, 18359, 103386, 100968, 119978, 627, 16, 13, 109760, 54780, 115036, 99901, 18918, 82818, 120378, 43139, 111964, 16582, 119978, 627, 17, 13, 115036, 99901, 19954, 108838, 109842, 18359, 111964, 16582, 113348, 117193, 96677, 119978, 627, 18, 13, 109760, 19954, 102597, 108386, 13094, 115036, 99901, 19954, 47782, 115300, 115036, 99901, 102772, 330, 34983, 65895, 109760, 93, 19954, 102597, 109842, 13094, 120078, 1210, 103959, 35495, 111964, 16582, 119978, 627, 19, 13, 111964, 48936, 54718, 103966, 30381, 117294, 18918, 119884, 83290, 54535, 41953, 108520, 54535, 101353, 18359, 114839, 101528, 33390, 107333, 19954, 102722, 102657, 16969, 23955, 101711, 84734, 17835, 95713, 117294, 85721, 48424, 18918, 102484, 21121, 119978, 13, 96717, 18918, 105510, 27796, 103966, 30381, 54535, 41953, 106593, 54535, 101353, 18359, 220, 16, 43144, 117294, 57575, 59777, 27797, 101528, 33390, 107333, 19954, 4416, 1116, 16, 5163, 110917, 55216, 58232, 16582, 119978, 627, 20, 13, 117294, 102772, 64857, 30446, 30426, 106943, 101438, 21028, 87134, 13094, 55216, 58232, 106910, 103924, 13, 41820, 108181, 109760, 44005, 106943, 101438, 73653, 18359, 127923, 101709, 115115, 95713, 117294, 73653, 18359, 59777, 27797, 83290, 111964, 16582, 119978, 627, 21, 13, 64857, 30446, 30426, 41820, 108181, 109760, 24486, 106943, 101438, 19954, 115825, 117294, 17835, 73653, 111964, 110513, 109670, 13, 106943, 101438, 13094, 105642, 117294, 18918, 110217, 106687, 59777, 27797, 88525, 96677, 119978, 271, 109070, 78326, 99901, 512, 35864, 52688, 27796, 16, 25, 107067, 100660, 100711, 13094, 75265, 117, 101272, 106446, 20, 4, 14852, 14711, 56773, 21028, 115790, 7, 16, 340, 21, 13, 58647, 119504, 56773, 21028, 115790, 198, 16, 8, 23955, 106943, 34804, 59777, 57390, 115602, 36439, 34609, 117622, 104323, 106647, 104064, 52976, 627, 17, 8, 101139, 119868, 21028, 104423, 13094, 35243, 123, 22035, 110661, 111003, 19954, 64432, 101106, 52976, 627, 18, 8, 101787, 103168, 101696, 18359, 102467, 54542, 107032, 21121, 57575, 8790, 117067, 96318, 32179, 105642, 107032, 109509, 64432, 101106, 44005, 110005, 101787, 103168, 101696, 74177, 27797, 19954, 122453, 33229, 35495, 113610, 106593, 101787, 103168, 101696, 121184, 198, 103194, 101464, 16582, 21028, 102467, 112215, 112098, 29833, 36439, 34609, 117622, 102467, 54542, 21028, 107032, 109509, 121942, 35495, 121916, 35243, 104, 54059, 64432, 101106, 52976, 627, 35864, 52688, 27796, 17, 25, 52491, 90335, 75265, 117, 101272, 106446, 20, 20939, 57139, 75265, 117, 30426, 67598, 250, 8, 14852, 14711, 56773, 21028, 115790, 7, 16, 340, 21, 13, 58647, 119504, 56773, 21028, 115790, 198, 16, 8, 23955, 106943, 34804, 59777, 57390, 115602, 36439, 34609, 117622, 104323, 106647, 104064, 52976, 627, 17, 8, 101139, 119868, 21028, 104423, 13094, 35243, 123, 22035, 110661, 111003, 19954, 64432, 101106, 52976, 627, 18, 8, 101787, 103168, 101696, 18359, 102467, 54542, 107032, 21121, 57575, 8790, 117067, 96318, 32179, 105642, 107032, 109509, 64432, 101106, 44005, 110005, 101787, 103168, 101696, 74177, 27797, 19954, 122453, 33229, 35495, 113610, 106593, 101787, 103168, 101696, 121184, 198, 103194, 101464, 16582, 21028, 102467, 112215, 112098, 29833, 36439, 34609, 117622, 102467, 54542, 21028, 107032, 109509, 121942, 35495, 121916, 35243, 104, 54059, 64432, 101106, 52976, 627, 35864, 52688, 27796, 18, 25, 103236, 110174, 121296, 106446, 20, 20939, 57139, 75265, 117, 30426, 67598, 250, 8, 14852, 14711, 56773, 21028, 115790, 7, 16, 340, 21, 13, 58647, 119504, 56773, 21028, 115790, 198, 16, 8, 23955, 106943, 34804, 59777, 57390, 115602, 36439, 34609, 117622, 104323, 106647, 104064, 52976, 627, 17, 8, 101139, 119868, 21028, 104423, 13094, 35243, 123, 22035, 110661, 111003, 19954, 64432, 101106, 52976, 627, 18, 8, 101787, 103168, 101696, 18359, 102467, 54542, 107032, 21121, 57575, 8790, 117067, 96318, 32179, 105642, 107032, 109509, 64432, 101106, 44005, 110005, 101787, 103168, 101696, 74177, 27797, 19954, 122453, 33229, 35495, 113610, 106593, 101787, 103168, 101696, 121184, 198, 103194, 101464, 16582, 21028, 102467, 112215, 112098, 29833, 36439, 34609, 117622, 102467, 54542, 21028, 107032, 109509, 121942, 35495, 121916, 35243, 104, 54059, 64432, 101106, 52976, 627, 35864, 52688, 27796, 19, 25, 103807, 101314, 96318, 63375, 101347, 103194, 108607, 94, 18550, 238, 7, 105711, 82233, 30426, 110076, 55055, 101518, 101868, 93917, 13879, 239, 25941, 8, 14852, 14711, 56773, 21028, 115790, 7, 16, 340, 20, 13, 58647, 119504, 56773, 21028, 115790, 198, 16, 8, 101139, 119868, 21028, 104423, 13094, 35243, 123, 22035, 110661, 111003, 19954, 64432, 101106, 48936, 72208, 627, 17, 8, 105164, 56154, 104176, 126712, 104064, 101360, 112098, 29833, 36439, 91040, 80307, 113, 109957, 103607, 35495, 90960, 105622, 24486, 111003, 19954, 114528, 66965, 83290, 7, 127038, 250, 103346, 239, 18359, 121916, 35243, 104, 54059, 8, 64432, 101106, 48936, 72208, 627, 18, 8, 101787, 103168, 101696, 18359, 102467, 54542, 107032, 21121, 57575, 8790, 117067, 96318, 32179, 105642, 107032, 109509, 64432, 101106, 44005, 110005, 101787, 103168, 101696, 74177, 27797, 7, 13467, 246, 120669, 41820, 121055, 101787, 24486, 33229, 35495, 102133, 77535, 106593, 720, 21028, 103168, 101696, 121184, 103194, 102678, 16582, 21028, 102467, 112215, 112098, 29833, 36439, 34609, 117622, 102467, 54542, 21028, 107032, 109509, 121942, 35495, 121916, 35243, 104, 54059, 64432, 101106, 48936, 72208, 627, 35864, 52688, 27796, 20, 25, 96677, 49706, 101796, 25941, 25941, 102477, 30446, 106446, 14852, 14711, 56773, 21028, 115790, 7, 16, 340, 21, 13, 58647, 119504, 56773, 21028, 115790, 198, 16, 8, 101139, 119868, 21028, 104423, 19954, 35243, 123, 22035, 110661, 111003, 19954, 64432, 101106, 48936, 72208, 627, 17, 8, 105164, 56154, 104176, 126712, 104064, 101360, 112098, 29833, 65621, 62398, 80307, 113, 109957, 103607, 34804, 90960, 105622, 24486, 111003, 19954, 320, 105711, 125986, 83290, 8, 64432, 101106, 48936, 72208, 627, 18, 8, 74177, 27797, 7, 13467, 246, 120669, 41820, 122369, 112925, 35495, 121184, 103194, 21028, 64432, 109074, 18359, 46810, 83290, 105642, 107032, 109509, 82818, 116407, 32179, 121942, 22035, 101264, 72208, 13, 128009, 128006, 882, 128007, 198, 98934, 100660, 100711, 13094, 75265, 117, 101272, 106446, 20, 4, 81673, 105642, 106943, 101438, 21028, 59134, 48424, 68611, 27797, 34804, 112700, 100027, 112795, 30, 128009, 128006, 78191, 128007, 198, 109070, 78326, 99901, 102772, 107067, 100660, 100711, 13094, 75265, 117, 101272, 106446, 20, 4, 81673, 105642, 106943, 101438, 21028, 59134, 48424, 68611, 27797, 18359, 107364, 18359, 29833, 120078, 13, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"input_ids\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input_ids 디코딩 결과:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 문서에는 반드시 약물의 이름이 기재되어 있습니다. 사용자가 질문하는 약물만을 정확히 찾아 해당 문서만을 인용하여 답변하십시오.\n",
      "6. 반드시 사용자가 질문한 약물에 관한 문서로만 답변해야 합니다. 약물이 다른 문서를 절대로 인용하지 마십시오\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 복합마이녹실액5% :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 이 약은 인화성이 있으므로 화기를 피한다.\n",
      "2) 어린이의 손이 닿지 않는 곳에 보관한다.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용에 따른 사고 발생이나 의약품 품\n",
      "질저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관한다.\n",
      "-----\n",
      "문서2: 메디녹실액5%(미녹시딜) :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 이 약은 인화성이 있으므로 화기를 피한다.\n",
      "2) 어린이의 손이 닿지 않는 곳에 보관한다.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용에 따른 사고 발생이나 의약품 품\n",
      "질저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관한다.\n",
      "-----\n",
      "문서3: 카필러스액5%(미녹시딜) :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 이 약은 인화성이 있으므로 화기를 피한다.\n",
      "2) 어린이의 손이 닿지 않는 곳에 보관한다.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용에 따른 사고 발생이나 의약품 품\n",
      "질저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관한다.\n",
      "-----\n",
      "문서4: 외유내간연질캡슐(밀크시슬열매건조엑스) :\n",
      "\n",
      "### 주의사항(1)\n",
      "5. 저장상의 주의사항\n",
      "1) 어린이의 손이 닿지 않는 곳에 보관할 것.\n",
      "2) 직사광선을 피하고 될 수 있으면 습기가 적고 서늘한 곳에 밀전하여(뚜껑을 꼭 닫아) 보관할 것.\n",
      "3) 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 의약품 오용(잘못 사용)에 의한 사고발생이나 \n",
      "의약품 품질 저하의 원인이 될 수 있으므로 원래의 용기에 넣고 꼭 닫아 보관할 것.\n",
      "-----\n",
      "문서5: 마그포스스피드액 :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 저장상의 주의사항\n",
      "1) 어린이의 손에 닿지 않는 곳에 보관할 것.\n",
      "2) 직사광선을 피하고 될 수 있는 한 습기가 적은 서늘한 곳에 (밀폐하여) 보관할 것.\n",
      "3) 오용(잘못 사용)을 막고 품질의 보존을 위하여 다른 용기에 바꾸어 넣지 말 것.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "복합마이녹실액5%와 다른 약물의 상호작용은 어떤 게 있어?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "검색 결과에는 복합마이녹실액5%와 다른 약물의 상호작용을 찾을 수 없습니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(\n",
    "    batch[\"input_ids\"][0].tolist(),\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\ninput_ids 디코딩 결과:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba81d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블에 대한 정수 인코딩 결과:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 109070, 78326, 99901, 102772, 107067, 100660, 100711, 13094, 75265, 117, 101272, 106446, 20, 4, 81673, 105642, 106943, 101438, 21028, 59134, 48424, 68611, 27797, 18359, 107364, 18359, 29833, 120078, 13, 128009]\n"
     ]
    }
   ],
   "source": [
    "print('레이블에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "labels 디코딩 결과 (-100 제외):\n",
      "검색 결과에는 복합마이녹실액5%와 다른 약물의 상호작용을 찾을 수 없습니다.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "label_ids = [token_id for token_id in batch[\"labels\"][0].tolist() if token_id != -100]\n",
    "\n",
    "decoded_labels = tokenizer.decode(\n",
    "    label_ids,\n",
    "    skip_special_tokens=False,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(\"\\nlabels 디코딩 결과 (-100 제외):\")\n",
    "print(decoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    max_seq_length=max_seq_length,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='594' max='594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [594/594 29:25, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.296800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.242200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.213600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.116300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.136200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.157100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.135800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.126900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.114700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.083200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.073600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.114700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.085200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd575f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for messages in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    input = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[0] + '<|start_header_id|>assistant<|end_header_id|>\\n'\n",
    "    label = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[1].split('<|eot_id|>')[0]\n",
    "    prompt_lst.append(input)\n",
    "    label_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
      "\n",
      "다음의 지시사항을 따르십시오.\n",
      "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
      "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
      "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문~에 대한 내용이 없습니다.\" 라고 답변하십시오.\n",
      "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오. 예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref1]]이라고 기재하십시오.\n",
      "5. 문서에는 반드시 약물의 이름이 기재되어 있습니다. 사용자가 질문하는 약물만을 정확히 찾아 해당 문서만을 인용하여 답변하십시오.\n",
      "6. 반드시 사용자가 질문한 약물에 관한 문서로만 답변해야 합니다. 약물이 다른 문서를 절대로 인용하지 마십시오\n",
      "\n",
      "검색 결과:\n",
      "-----\n",
      "문서1: 욱씬정 :\n",
      "\n",
      "### 주의사항(1)\n",
      "1. 경고\n",
      "1) 매일 세잔 이상 정기적으로 술을 마시는 사람이 이 약이나 다른 해열진통제를 복용해야 할\n",
      "경우 반드시 의사 또는 약사와 상의해야 한다. 이러한 사람이 이 약을 복용하면 간손상이 유\n",
      "발될 수 있다.\n",
      "2) 아세트아미노펜을 복용한 환자에서 매우 드물게 급성 전신성 발진성 농포증(급성 전신성 발\n",
      "진성 고름물집증)(AGEP), 스티븐스 - 존슨 증후군(SJS), 독성 표피 괴사용해(TEN)와 같은 중대\n",
      "한 피부 반응이 보고되었고, 이러한 중대한 피부반응은 치명적일 수 있다. 따라서 이러한 중대한\n",
      "피부반응의 징후에 대하여 환자들에게 충분히 알리고, 이 약 투여 후 피부발진이나 다른 과민반\n",
      "응의 징후가 나타나면 즉시 복용을 중단하도록 하여야 한다.\n",
      "3) 이 약은 아세트아미노펜을 함유하고 있다. 아세트아미노펜으로 일일 최대 용량(4,000mg)을\n",
      "초과할 경우 간손상을 일으킬 수 있으므로 이 약을 일일 최대 용량(4000mg)을 초과하여 복용\n",
      "하여서는 아니되며, 아세트아미노펜을 포함하는 다른 제품과 함께 복용하여서는 안 된다.\n",
      "-----\n",
      "문서2: 나노텍정(세티리진염산염) :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 기타 이 약의 복용(사용)시 주의할 사항\n",
      "1) 이 약은 알레르기항원피내반응을 억제하므로 알레르기항원피내반응검사를 실시하기 3 ∼ 5일 전에는 이 \n",
      "약을 투여하지 않는 것이 바람직하다.\n",
      "2) 건강한 지원자에게 1일 20 ∼ 25 mg을 투여한 결과, 민첩성이나 반응시간에 어떠한 부작용도 나타내지 \n",
      "않았으나 운전이나 기계조작 시에는 용량을 초과하지 않는다. 라세미체(광학이성질체)가 알코올의 영향을 증\n",
      "가시키지 않을 것으로 보여지나(0.5 g/L 혈액 수준), 알코올 또는 기타 CNS 억제제를 병용 투여하면 경계심\n",
      "이 추가로 감소될 수 있고 수행 장애를 야기할 수 있다.\n",
      "3) 증상에 따라 이 약으로서 1일 10mg 투여로 개선이 없을 경우, 의사 또는 약사의 지시에 따라 1일 20mg\n",
      "까지 투여한 임상보고가 있다.\n",
      "4) 세티리진의 흡수 속도는 음식물에 의해 1시간 정도 감소되지만, 흡수 정도는 감소되지 않는다.\n",
      "-----\n",
      "문서3: 액티피드정 :\n",
      "\n",
      "### 주의사항(1)\n",
      "3. 이 약을 복용하는 동안 다음의 약을 복용하지 말 것.\n",
      "1) 혈압강하제, 알코올, 중추신경억제제(수면제, 진정제, 안정제), MAO 억제제, 교감신경흥분제, 삼환계 항\n",
      "우울약, 구아네티딘, 브레틸리움, 베타나이드, 데브리소퀸, 메칠도파, 교감신경성약(충혈제거제, 식욕억제\n",
      "제, 암페타민류의 신경자극제), α 및 β 아드레날린 저해제(억제제)와 병용(함께 복용)투여하지 않는다.\n",
      "2) MAO억제제의 긴 작용시간 때문에 MAO억제제 투여 최소 15일 후 이 약을 투여한다.\n",
      "-----\n",
      "문서4: 알지텍정(세티리진염산염) :\n",
      "\n",
      "### 주의사항(1)\n",
      "6. 기타 이 약의 복용(사용)시 주의할 사항\n",
      "1) 이 약은 알레르기항원피내반응을 억제하므로 알레르기항원피내반응검사를 실시하기 3 ∼ 5일 전에는 이 \n",
      "약을 투여하지 않는 것이 바람직하다.\n",
      "2) 건강한 지원자에게 1일 20 ∼ 25 mg을 투여한 결과, 민첩성이나 반응시간에 어떠한 부작용도 나타내지 \n",
      "않았으나 운전이나 기계조작 시에는 용량을 초과하지 않는다. 라세미체(광학이성질체)가 알코올의 영향을 증\n",
      "가시키지 않을 것으로 보여지나(0.5 g/L 혈액 수준), 알코올 또는 기타 CNS 억제제를 병용 투여하면 경계심\n",
      "이 추가로 감소될 수 있고 수행 장애를 야기할 수 있다.\n",
      "\n",
      "3) 증상에 따라 이 약으로서 1일 10mg 투여로 개선이 없을 경우, 의사 또는 약사의 지시에 따라 1일 20mg\n",
      "까지 투여한 임상보고가 있다.\n",
      "4) 세티리진의 흡수 속도는 음식물에 의해 1시간 정도 감소되지만, 흡수 정도는 감소되지 않는다.\n",
      "-----\n",
      "문서5: 자니틴정(니자티딘) :\n",
      "\n",
      "### 주의사항(1)\n",
      "3. 이 약을 복용하는 동안 다음의 행위를 하지 말 것.\n",
      "알코올 음료를 마시는 경우<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "자니틴정은 복용 중 알코올 음주가 금지되나요?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_lst[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29464e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "자니틴정(니자티딘)을 복용하는 동안에는 알코올 음료를 마시는 것이 금지됩니다. [[ref5]]\n"
     ]
    }
   ],
   "source": [
    "print(label_lst[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b62ae1",
   "metadata": {},
   "source": [
    "- base model에 붙여 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4a4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269a2a017e9d415d8e3faef75e3add5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"NCSOFT/Llama-VARCO-8B-Instruct\"  \n",
    "peft_model_id = \"llama-3-8b-otc-rag-ko/checkpoint-594\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},  # GPU 0번\n",
    ")\n",
    "fine_tuned_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    peft_model_id,\n",
    ")\n",
    "pipe = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = tokenizer(\"<|eot_id|>\",add_special_tokens=False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens=1024, eos_token_id=eos_token, do_sample=False)\n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd95329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "자니틴정 복용 중에는 알코올 음주가 금지됩니다. 이 약을 복용하는 동안에는 알코올 음료를 마시는 것을 피해야 합니다[[ref5]].\n",
      "    label:\n",
      "\n",
      "자니틴정(니자티딘)을 복용하는 동안에는 알코올 음료를 마시는 것이 금지됩니다. [[ref5]]\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "타라부틴정 복용 시 드물게 나타날 수 있는 소화기계 이상반응은 변비, 설사, 복명(창자 가스소리), 구역, 구토, 소화장애, 구갈(목마름), 구내마비감 등입니다[[ref1]].\n",
      "    label:\n",
      "\n",
      "타라부틴정 복용 시 드물게 나타날 수 있는 소화기계 이상반응으로는 변비, 설사, 복명(창자 가스소리), 구역, 구토, 소화장애, 구갈(목마름), 구내(입안)마비감 등이 있습니다[[ref1]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "써큐록신정 120밀리그램의 성인 용법은 말초동맥 순환장애, 어지러움, 이명 등의 증상을 치료하기 위해 1회 40mg을 1일 3회 또는 1회 80mg을 1일 2회 경구투여하는 것입니다. 또한, 기질성 뇌기능 장애를 다루기 위해서는 1회 40 ~ 80mg을 1일 3회 또는 1회 120mg을 1일 2회 경구 투여합니다. 연령과 증상에 따라 적절히 증감할 수 있습니다[[ref3]].\n",
      "    label:\n",
      "\n",
      "써큐록신정 120밀리그램의 성인 용법은 다음과 같습니다. 말초동맥 순환장애, 어지러움, 이명에 대해서는 1회 40mg을 1일 3회 또는 1회 80mg을 1일 2회 경구 투여하며, 기질성 뇌기능 장애에 대해서는 1회 40 ~ 80mg을 1일 3회 또는 1회 120mg을 1일 2회 경구 투여합니다. 연령과 증상에 따라 적절히 증감할 수 있습니다[[ref3]].\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for prompt, label in zip(prompt_lst[100:103], label_lst[100:103]):\n",
    "    # print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17894c13",
   "metadata": {},
   "source": [
    "- 모델, 토크나이저 저장 후 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model from: NCSOFT/Llama-VARCO-8B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c87a79c7e214c80b0816456545e6d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging PEFT from: ./llama-3-8b-otc-rag-ko/checkpoint-594\n",
      "Saving merged model to: ./output_dir\n",
      "✅ 모델과 토크나이저 저장 완료\n"
     ]
    }
   ],
   "source": [
    "base_model_path = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
    "adapter_path = \"./llama-3-8b-otc-rag-ko/checkpoint-594\"\n",
    "merged_model_path = \"./output_dir\"\n",
    "\n",
    "device_arg = {\"device_map\": \"auto\"}\n",
    "\n",
    "print(f\"Loading base model from: {base_model_path}\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    **device_arg\n",
    ")\n",
    "\n",
    "print(f\"Loading and merging PEFT from: {adapter_path}\")\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path, **device_arg)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "print(f\"Saving merged model to: {merged_model_path}\")\n",
    "model.save_pretrained(merged_model_path)\n",
    "tokenizer.save_pretrained(merged_model_path)\n",
    "print(\"✅ 모델과 토크나이저 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'NCSOFT/Llama-VARCO-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "prompt_lst = []\n",
    "label_lst = []\n",
    "\n",
    "for messages in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    input = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[0] + '<|start_header_id|>assistant<|end_header_id|>\\n'\n",
    "    label = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[1].split('<|eot_id|>')[0]\n",
    "    prompt_lst.append(input)\n",
    "    label_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = tokenizer(\"<|eot_id|>\",add_special_tokens=False)[\"input_ids\"][0]\n",
    "\n",
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens=1024, eos_token_id=eos_token, do_sample=False)\n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7870a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4587bb2702ae43ac92c355aefced6005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    response:\n",
      "훼리맘큐연질캡슐은 12세 이상의 어린이와 성인이 1일 1회, 1회 1캡슐을 복용해야 합니다[[ref2]].\n",
      "    label:\n",
      "\n",
      "훼리맘큐연질캡슐은 12세 이상 어린이 및 성인이 1일 1회, 1회 1캡슐을 복용하도록 되어 있습니다[[ref2]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "포머렐정은 어린이의 손이 닿지 않는 곳에 보관해야 하며, 다른 용기에 바꾸어 넣는 것은 사고의 원인이 될 수 있으므로 주의해야 합니다. [[ref1]]\n",
      "    label:\n",
      "\n",
      "포머렐정은 어린이의 손이 닿지 않는 곳에 보관해야 하며, 의약품을 원래 용기에서 꺼내어 다른 용기에 보관하는 것은 사고의 원인이 되거나 품질 유지에 바람직하지 않으므로 주의해야 합니다[[ref1]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "니자티드정은 성인이 하루에 75 mg을 경구투여할 수 있으며, 증상의 개선이 없을 경우 추가로 75 mg을 투여할 수 있습니다. 그러나 1일 최대 복용량은 150 mg을 초과할 수 없습니다[[ref5]].\n",
      "    label:\n",
      "\n",
      "니자티드정(니자티딘)의 경우, 성인은 하루에 1회 75 mg을 복용할 수 있으며, 증상의 개선이 없을 경우 8시간 후에 추가로 75 mg을 투여할 수 있습니다. 그러나 1일 최대 복용량은 150 mg을 초과할 수 없습니다[[ref5]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "가스키환은 임신 가능성이 있는 여성에게 복용하지 말아야 합니다. 이 약은 신생아, 수유부, 임부 또는 임신하고 있을 가능성이 있는 여성에게 복용하지 말아야 한다고 명시되어 있습니다[[ref5]].\n",
      "    label:\n",
      "\n",
      "가스키환은 임부 또는 임신하고 있을 가능성이 있는 여성에게 복용하지 말아야 합니다. 이 약물은 이러한 여성에게 안전성이 확립되지 않았으므로 복용을 피해야 합니다[[ref5]].\n",
      "--------------------------------------------------\n",
      "    response:\n",
      "콜록콜드시럽은 어린이의 손에 닿지 않는 장소에 보관해야 하며, 직사광선을 피하고 습기가 적은 서늘한 곳에 밀폐하여 보관해야 합니다. 또한, 오용을 막고 품질을 보존하기 위해 다른 용기에 바꾸어 넣지 말아야 합니다[[ref1]].\n",
      "    label:\n",
      "\n",
      "콜록콜드시럽은 어린이의 손에 닿지 않는 장소에 보관해야 하며, 직사광선을 피하고 습기가 적은 서늘한 곳에 밀폐하여 보관하는 것이 좋습니다. 또한, 오용을 막고 품질을 보존하기 위해 다른 용기에 바꾸어 넣지 않아야 합니다[[ref1]].\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_id = './output_dir'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "for prompt, label in zip(prompt_lst[150:155], label_lst[150:155]):\n",
    "    print(f\"    response:\\n{test_inference(pipe, prompt)}\")\n",
    "    print(f\"    label:\\n{label}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f1da4",
   "metadata": {},
   "source": [
    "- 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "\n",
    "username = \"eddyfox8812\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d44c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"llama-3-8b-otc-rag-ko-checkpotint-594\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a5c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8ca207c5a649f9a8575eecd645b84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5446b0f8ad4c42c2982f0c12848d00b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api.create_repo(\n",
    "    token=\"api key\",\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "api.upload_folder(\n",
    "    token=\"api key\",\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    folder_path=\"output_dir\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
