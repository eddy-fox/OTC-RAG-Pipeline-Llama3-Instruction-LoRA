{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4738edae",
   "metadata": {},
   "source": [
    "# **프로젝트**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb393e4",
   "metadata": {},
   "source": [
    "# 프로젝트 명:\n",
    "일반의약품 복용·주의사항 근거기반 QA 시스템: RAG 구축 및 Llama 3 Instruction-LoRA 미세조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6a734",
   "metadata": {},
   "source": [
    "# 목차\n",
    "A. 프로젝트 개요\n",
    "  - 프로젝트명\n",
    "  - 프로젝트를 들어가며\n",
    "  - 사용된 개발환경, 패키지, 툴, 응용프로그램\n",
    "  - 프로젝트의 목표\n",
    "\n",
    "B. 작업 계획\n",
    "  - gantt chart\n",
    "  - 작업 순서도\n",
    "\n",
    "C. 데이터 처리\n",
    "  - phase 1. 데이터 수집/저장\n",
    "    - 1.1 데이터 소스 설명\n",
    "    - 1.2 수집 방법\n",
    "  - phase 2. 데이터 전처리\n",
    "    - 2.1 데이터 전처리\n",
    "    - 2.2 PDF 로딩/정제\n",
    "    - 2.3 청킹 전략\n",
    "    - 2.4 데이터 품질 점검\n",
    "    - 2.5 학습 데이터셋 생성\n",
    "D. RAG 구축 및 모델링/평가\n",
    "  - phase 3. RAG 파이프라인 구축\n",
    "    - 3.1 임베딩 모델\n",
    "    - 3.2 벡터DB 및 인덱싱\n",
    "    - 3.3 검색 전략\n",
    "    - 3.4 프롬프트 설계\n",
    "    - 3.5 생성 모델 서빙 및 RAG Inference\n",
    "  - phase 4. LLM 미세조정\n",
    "    - 4.1 학습 데이터 구성\n",
    "    - 4.2 학습 설정\n",
    "    - 4.3 평가 방법\n",
    "    - 4.4 결과 분석\n",
    "    - 4.5 한계 및 개선 방향\n",
    "E. 응용 및 배포\n",
    "  - phase 5. 응용 어플리케이션\n",
    "    - 5.1 서비스 개요\n",
    "    - 5.2 시스템 아키텍처\n",
    "    - 5.3 구현\n",
    "    - 5.4 운영 고려사항\n",
    "F. 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a436c20",
   "metadata": {},
   "source": [
    "# A. 프로젝트 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335bc1c",
   "metadata": {},
   "source": [
    "## 프로젝트명\n",
    "일반의약품 복용·주의사항 근거기반 QA 시스템: RAG 구축 및 Llama 3 Instruction-LoRA 미세조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf6100",
   "metadata": {},
   "source": [
    "## 프로젝트를 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ca057",
   "metadata": {},
   "source": [
    "일반의약품(OTC)은 의사 처방 없이 약국에서 손쉽게 구매할 수 있어 접근성이 높지만, 실제 복용 과정에서는 개인의 상황에 따라 “지금 이 약을 먹어도 되는지”를 판단해야 하는 순간이 자주 발생한다. 예를 들어 음주 전후 복용 가능 여부, 다른 의약품과의 병용 가능성, 임신·수유 중 복용 제한 등은 약효 저하나 부작용과 직접 연결될 수 있어 정확한 확인이 필요하다. 그러나 소비자는 이러한 정보를 제품 설명서나 인터넷 검색을 통해 흩어진 정보를 찾아야 하며, 용어가 어렵거나 자료의 신뢰도가 제각각이라 필요한 답을 빠르게 얻기 어렵다.\n",
    "\n",
    "최근 ChatGPT, Gemini 같은 AI 챗봇이 활성화되면서 정보 탐색의 수고는 줄었지만, 일반 LLM은 근거 없는 답을 그럴듯하게 생성하는 할루시네이션 문제가 있어 의료·약학 정보처럼 정확성이 중요한 영역에서는 결과를 온전히 신뢰하기 어렵다.\n",
    "\n",
    "따라서 본 프로젝트는 약국에서 처방 없이 구매 가능한 일반의약품 약 만여 종의 주성분, 복용법(용법·용량), 사용상의 주의사항을 문서 기반으로 정리하고, 이를 Llama 모델에 RAG(검색 기반 생성) 및 미세조정 방식으로 적용해 사용자가 자신의 상황에 맞는 복용 정보를 빠르고 근거 기반으로 확인할 수 있도록 하는 것을 목표로 한다. 이를 통해 소비자의 안전한 의약품 사용을 돕고, 신뢰 가능한 복약 정보 접근성을 높이는 의의를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e0ea37",
   "metadata": {},
   "source": [
    "### 사용된 개발환경, 패키지, 툴, 응용프로그램"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff4c42",
   "metadata": {},
   "source": [
    "프로그래밍 언어: Python3 <br>\n",
    "데이터 수집: requests <br>\n",
    "데이터 전처리: pandas, PyPDF2 <br>\n",
    "문서 로딩/청킹: langchain_community, langchain_text_splitters <br>\n",
    "임베딩/벡터DB: langchain_community <br>\n",
    "기본 LLM 모델(파인튜닝 베이스): NCSOFT/Llama-VARCO-8B-Instruct <br>\n",
    "전처리 질문, 응답 생성 : OpenAI gpt-4o-mini <br>\n",
    "RAG 구현: LangChain + Chroma(VectorStore) <br>\n",
    "LLM 파인튜닝(LoRA/SFT): transformers, peft, trl, torch<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba149d1",
   "metadata": {},
   "source": [
    "# 프로젝트에 고려할 수 있는 AI 서비스 & API (유, 무료)\n",
    "\n",
    "- 의약품안전나라-의약품통합정보시스템(website) : 일반의약품 품목 정보(주성분/용법·용량/주의사항 등) 원천 데이터 조회 및 수집\n",
    "- Hugging Face(website) : 사전학습(기본) 모델(NCSOFT/Llama-VARCO-8B-Instruct) 로드·배포, 전처리한 데이터셋/파인튜닝 모델(LoRA 어댑터 포함) 업로드 및 버전 관리, 오픈소스 라이브러리(Transformers/PEFT/TRL) 활용\n",
    "- RunPod(website) : 파인튜닝 및 임베딩/벡터DB 구축 등 고연산 작업을 위한 GPU 인스턴스 대여(학습 환경 구성, VRAM 기반 실험/학습 실행)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16558e8",
   "metadata": {},
   "source": [
    "## 프로젝트의 목표\n",
    "만여 종 일반의약품의 주성분·용법/용량·사용상 주의사항 문서를 기반으로 Llama 모델에 RAG와 미세조정을 적용해, 음주·임신/수유·병용 등 개인 상황별 복용 가능 여부를 할루시네이션을 줄인 근거 기반 답변으로 빠르고 정확하게 안내한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708f517",
   "metadata": {},
   "source": [
    "# B. 작업계획"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497e53d",
   "metadata": {},
   "source": [
    "# C. 데이터 처리 및 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d84376",
   "metadata": {},
   "source": [
    "[데이터 정제 code](https://github.com/eddy-fox/OTC-RAG-Pipeline-Llama3-Instruction-LoRA/blob/main/1.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%95%EC%A0%9Ccode.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c91fd1",
   "metadata": {},
   "source": [
    "## Phase1. 데이터 수집 및 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8f0dc",
   "metadata": {},
   "source": [
    "### 1.1 데이터 소스 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a75a04",
   "metadata": {},
   "source": [
    "##### - 의약품 제품허가 상세정보(df)\n",
    "1. 출처 : nedrug.mfds.go.kr (website)\n",
    "2. 데이터프레임 예시 : <br>\n",
    "\n",
    "| index | 품목명                                            | 품목 영문명                                      |    품목일련번호 | 허가/신고구분 | 취소상태 | 취소일자 |       변경일자 | 업체명          | 업체 영문명                  |     허가일자 | ... | 신약여부 | 업종구분 | 변경내용                                              | 총량        | 주성분명                        | 첨가제명          | ATC코드   |        사업자번호 | 희귀의약품여부 | 위탁제조업체       |\n",
    "| ----: | ---------------------------------------------- | ------------------------------------------- | --------: | ------- | ---- | ---- | ---------: | ------------ | ----------------------- | -------: | --- | ---- | ---- | ------------------------------------------------- | --------- | --------------------------- | ------------- | ------- | -----------: | ------- | ------------ |\n",
    "|     0 | 중외5%포도당생리식염액(수출명:5%DextroseinnormalsalineInj.) | Choongwae 5% Dextrose In Normal Saline Inj. | 195500005 | 신고      | 정상   | NaN  | 20210827.0 | 제이더블유중외제약(주) | JW Pharmaceutical       | 19550412 | ... | NaN  | 의약품  | 저장방법 및 사용(유효)기간, 2021-08-27/성상, 2021-08-27/저장방... | 1000      | [M040702]포도당[M040426]염화나트륨 | [M040534]주사용수 | B05BB02 | 1.188102e+09 | NaN     | 제이더블유생명과학(주) |\n",
    "|     1 | 중외5%포도당주사액                                     | JW 5% Dextrose Injection                    | 195500006 | 신고      | 정상   | NaN  | 20210820.0 | 제이더블유중외제약(주) | JW Pharmaceutical       | 19550413 | ... | NaN  | 의약품  | 성상, 2021-08-20/성상변경, 2019-07-30/사용상주의사항변경(부작용포... | 1000      | [M040702]포도당                | [M040534]주사용수 | B05BA03 | 1.188102e+09 | N       | 제이더블유생명과학(주) |\n",
    "|     2 | 중외20%포도당주사액                                    | JW Glucose Injection 20%                    | 195600004 | 신고      | 정상   | NaN  | 20210917.0 | 제이더블유중외제약(주) | JW Pharmaceutical       | 19561129 | ... | NaN  | 의약품  | 성상, 2021-09-17/저장방법 및 사용(유효)기간, 2021-09-17/저장방... | 1000밀리리터중 | [M040702]포도당                | [M040534]주사용수 | B05BA03 | 1.188102e+09 | N       | 제이더블유생명과학(주) |\n",
    "|     3 | 중외50%포도당주사액                                    | JW 50% Dextrose Injection                   | 195600006 | 신고      | 정상   | NaN  | 20210820.0 | 제이더블유중외제약(주) | JW Pharmaceutical       | 19561128 | ... | NaN  | 의약품  | 성상, 2021-08-20/저장방법 및 사용(유효)기간, 2021-08-20/저장방... | 1000밀리리터중 | [M040702]포도당                | [M040534]주사용수 | B05BA03 | 1.188102e+09 | N       | 제이더블유생명과학(주) |\n",
    "|     4 | 대한포도당주사액(10%)                                  | Dai Han Dextrose Injection(10%)             | 195700004 | 신고      | 정상   | NaN  | 20190909.0 | 대한약품공업(주)    | DAI HAN PHARM CO., LTD. | 19570614 | ... | NaN  | 의약품  | 성상변경, 2019-09-09/저장방법 및 유효기간(사용기간)변경, 2019-09-... | 100밀리리터 중 | [M040702]포도당                | [M040534]주사용수 | B05BA03 | 1.348500e+09 | N       | NaN          |\n",
    "\n",
    "3. 데이터 크기(shape) : (44045, 38)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5129fc1",
   "metadata": {},
   "source": [
    "### 1.2 데이터 수집 방법\n",
    "의약품통합정보시스템에서 제공하는 공공데이터 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc109ba",
   "metadata": {},
   "source": [
    "## phase 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f4a99",
   "metadata": {},
   "source": [
    "### 2.1 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5216f4",
   "metadata": {},
   "source": [
    "(1) [전문의약]열에서 '일반의약품'값을 가진 열만 따로 추출 <br>\n",
    "(2) [\"품목명\", \"전문일반\", \"용법용량\",\"주성분명\", \"주의사항\", \"취소상태\", \"취소일자\", \"변경내용\"] 열만 추출 <br>\n",
    "(3) [\"취소상태\"]열이 \"정상\"인 값만 추출 <br>\n",
    "\n",
    "\n",
    "\n",
    "| 번호 | 품목명 | 전문일반 | 용법용량 | 주성분명 | 주의사항 | 취소상태 | 취소일자 | 변경내용 |\n",
    "|---:|---|---|---|---|---|---|---|---|\n",
    "| 13 | 활명수 | 일반의약품 | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | [M279284]L-멘톨\\[M050036]육계\\[M040548]창출[M040538... | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | 정상 | NaN | 용법·용량, 2022-04-14/사용상주의사항변경(부작용포함), 2019-06-20... |\n",
    "| 18 | 신신티눈고(살리실산반창고)(수출명:SINSINCORNPLASTER) | 일반의약품 | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | [M040264]살리실산 | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | 정상 | NaN | 성상변경, 2015-10-30/사용상주의사항변경(부작용포함), 2014-04-25/... |\n",
    "| 19 | 아네모정 | 일반의약품 | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | [M099577]스코폴리아엑스10배산\\[M040631]탄산수소나트륨\\[M040634... | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | 정상 | NaN | 사용상주의사항변경(부작용포함), 2014-11-07/효능효과변경, 2014-11-0... |\n",
    "| 20 | 자모 | 일반의약품 | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | [M040048]길경\\[M050058]구아이페네신\\[M040482]원지\\[M0402... | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | 정상 | NaN | 사용상의 주의사항, 2024-09-12/사용상주의사항변경(부작용포함), 2015-0... |\n",
    "| 25 | 페니라민정(클로르페니라민말레산염) | 일반의약품 | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | [M223211]클로르페니라민말레산염 | https://nedrug.mfds.go.kr/pbp/cmn/pdfDownload/... | 정상 | NaN | 효능효과변경, 2019-08-26/사용상주의사항변경(부작용포함), 2019-08-2... |\n",
    "\n",
    "- shape : (8650, 8)\n",
    "<br><br>\n",
    "(4) 용법용량, 주의사항은 PDF파일 다운로드 링크이므로 배치 다운로드 스크립트를 활용해 '약물명_용법용량.pdf','약물명_주의사항.pdf'로 각각 저장 (17,298개 파일) <br>\n",
    "(5) 다운로드 실패한 파일의 데이터 삭제 (1행)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95562bc",
   "metadata": {},
   "source": [
    "### 2.2 PDF 로딩/정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4a08d",
   "metadata": {},
   "source": [
    "- 1. PyPDF2를 사용하여 텍스트를 추출하고 페이지를 합쳐서 반환 (def extract_text_from_pdf)\n",
    "- 2. 텍스트 정규화 (def normalize_text)\n",
    "    - 줄바꿈을 \\n으로 통일\n",
    "    - 제어분자를 공백으로 치환\n",
    "    - 공백 혹은 탭이 여러번 연속되면 공백 1개로 압축\n",
    "    - 줄바꿈이 3번 이상이면 2번으로 줄임\n",
    "    - 앞뒤 공백, 줄바꿈 제거\n",
    "- 3. 파일명에서 약물명과 섹션을 구분 (def parse_fimename)\n",
    "    - 약물명_용법용량.pdf, 약물명_주의사항.pdf 의 규칙으로 파일명이 설정되어있어 '_'을 기준으로 앞은 약물명, 뒤는 섹션으로 구분\n",
    "- 4. 메인함수 (def build_two_chunks)\n",
    "    - 약물별로 PDF 묶기 (drug_map)\n",
    "    - extract_text_from_pdf 로 용법용량, 주의사항 텍스트 만들어 각각 dose_text, warn_text로 저장\n",
    "    - dose_text와 warn_text에 내용이 있으면 저장.\n",
    "        - 현재 파일 내부에는 약물명이 없으므로, 저장시에 약물명을 텍스트 앞부분에 붙여 저장\n",
    "    - 용법용량과 주의사항이 없으면 텍스트 추출 실패로 간주하고 해당 약물명을 empty_drugs에 따로 저장\n",
    "    - 마지막 요약출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee8a07b",
   "metadata": {},
   "source": [
    "### 2.3 청킹 전략"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6c575",
   "metadata": {},
   "source": [
    "1) 약물종류별 복용방법 / 주의사항 으로 청킹\n",
    "2) 복용방법이 긴 약물은 1500자 길이로 청킹\n",
    "2) 주의사항이 긴 약물은 정확도가 떨어질 것을 대비해 약물명, 주성분, 약물코드를 메타데이터로 주입한 후 청킹\n",
    "3) 주의사항은 대번호(1,2,3,...)를 기준으로 묶되 최대 길이 상한을 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f56ea",
   "metadata": {},
   "source": [
    "### 2.4 데이터 품질 점검"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7678db",
   "metadata": {},
   "source": [
    "drug_id–section 단위의 sub_index(1…sub_count) 연속성 검증 결과 누락/중복이 없었고, 필수 메타데이터 및 chunk_id 중복 문제도 확인되지 않았다. 길이 분포는 총 64,015개 청크 기준 평균 399자, 중앙값 287자이며, P90 838자·P95 약 1,105자·P99 1,533자(최대 1,887자)로 나타났다. 각 청크 당 헤더를 제외하면 최대 1500자로 길지만 비율이 매우 적다. 이를 종합하면 본 청킹 데이터는 RAG 인덱싱 및 QA 데이터셋 생성에 활용하기에 충분한 품질을 확보한 것으로 판단된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0c5f9",
   "metadata": {},
   "source": [
    "### 2.5 학습 데이터셋 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab02b1",
   "metadata": {},
   "source": [
    "- 청킹데이터에서 메타데이터의 약물명을 기준으로하여 용법용량 500건, 주의사항 8149건의 문서에서 청크를 뽑아 context 생성\n",
    "    - 실사용 질의의 대부분이 주의사항으로 집중될 것으로 가정하여 주의사항의 비중을 높게 구성\n",
    "    - context는 단일 chunk를 사용하여 구성\n",
    "- 1000여건의 샘플데이터로 QA 데이터셋을 제작하기로 결정\n",
    "    - OpenAI Fine-tuning 가이드에서는 약 500건 수준의 데이터로도 파인튜닝이 가능하다<sup>1)</sup> 고 안내하지만, 관련 연구에서 GPT-4 기반 실험 시 1,000개 데이터셋이 연구 목적의 최소 단위로 활용된 사례를 확인<sup>2)</sup>. <br>\n",
    "        - 출처 : <sup>1)</sup>[\"OPENAI Developers-Supervised fine-tuning\"](https://developers.openai.com/api/docs/guides/supervised-fine-tuning), <sup>2)</sup>[\"Instruction Tuning for Large Language Models: A Survey\"](https://arxiv.org/html/2308.10792v5)\n",
    "    - 이에 따라 학습 비용과 데이터 생성 비용을 함께 고려해 1,000건으로 1차 SFT를 수행하고, 성능 검증 결과에 따라 점진적으로 데이터 규모를 확장할 예정.\n",
    "    - 각 약물별 주의사항 길이의 차이로 청킹된 문서 수가 다르기 때문에 층화추출로 과적합 방지\n",
    "- QA 생성 품질은 파라미터 규모에 따른 성능 차이가 크기 때문에 Llama-8B 대신, 비용 대비 성능이 우수한 GPT 계열 모델인 gpt-4o-mini를 활용해 QA 데이터를 생성.<sup>3)</sup>\n",
    "    - 출처 : <sup>3)</sup> [\"OPENAI Developers-Pricing\"](https://developers.openai.com/api/docs/pricing/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9acec97",
   "metadata": {},
   "source": [
    "# D. RAG 구축 및 모델링/평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba340fef",
   "metadata": {},
   "source": [
    "[RAG 구축 code](https://github.com/eddy-fox/OTC-RAG-Pipeline-Llama3-Instruction-LoRA/blob/main/2.%20RAG%20%EA%B5%AC%EC%B6%95%20code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598dc85",
   "metadata": {},
   "source": [
    "## phase 3. RAG 파이프라인 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d158d",
   "metadata": {},
   "source": [
    "### 3.1 임베딩 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd5f1e",
   "metadata": {},
   "source": [
    "- BAAI/bge-m3\n",
    "    - 한국어 최적화로 약물명 질의를 정확히 검색\n",
    "    - 1500자 수준의 긴 주의사항 커버 가능\n",
    "    - 고속 임베딩 처리 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc5ae4",
   "metadata": {},
   "source": [
    "### 3.2 벡터DB 및 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315eb020",
   "metadata": {},
   "source": [
    "- Vector DB: Chroma (로컬 Persist)\n",
    "- 인덱싱 단위: 1 Chunk = 1 Vector\n",
    "    - chunk_id를 고유 키로 사용 (예: a93187414074-warn-1)\n",
    "- 메타데이터 스키마(약물명필터용)\n",
    "    - 약물 식별: drug_id, drug_name, drug_name_key\n",
    "    - 성분/분류: active_ingredient, pro_type(일반의약품)\n",
    "    - 섹션 구분: section (예: 주의사항)\n",
    "    - 원문 순서 복원: sub_index(1…sub_count), sub_count\n",
    "- 검색 품질 이점\n",
    "    - drug_id + section 필터로 특정 약물/항목 내 정밀 검색\n",
    "    - sub_index 기반으로 검색 결과를 원문 순서대로 재조합(근거 문장 연결) 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40e942",
   "metadata": {},
   "source": [
    "### 3.3 검색 전략"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc23c5",
   "metadata": {},
   "source": [
    "1) 약물명 사전 구축(메타데이터 기반)\n",
    "\n",
    "    - 사용자 질의에서 약물명을 빠르게 식별하고, 이후 검색을 해당 약물로 제한(filter)하기 위해 Chroma 컬렉션에서 metadatas.drug_name을 배치(limit/offset)로 순회하여 유니크 약물명 리스트(drug_names)를 생성<br>\n",
    "2) 질의 전처리 및 약물명 후보 추출(lexical match)\n",
    "    - 사용자 질의에서 정규표현식으로 토큰 추출 후 각 토큰이 포함되는 drug_name 후보들을 탐색하여, 후보를 가장 많이 생성하는 토큰(best_token)을 선택\n",
    "    - 후보 리스트는 길이 기준 정렬 후 top_n만 유지(과도한 후보 방지) <br>\n",
    "3) 약물명 결정(대화형)\n",
    "    - 후보가 존재하면 사용자에게 목록을 보여주고 하나를 선택 \n",
    "    - 후보가 없으면 drug_name 필터 없이 진행<br>  \n",
    "4) 최종 검색: 메타데이터 필터 + 벡터 유사도 검색\n",
    "    - 약물명이 결정된 경우 특정 약물 범위 내에서 의미 기반 검색을 수행하여 정밀도 상승\n",
    "    - 약물명이 결정되지 않은 경우 전체 코퍼스 의미 검색으로 리콜(Recall) 확보"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594daeaa",
   "metadata": {},
   "source": [
    "### 3.4 프롬프트 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a358a",
   "metadata": {},
   "source": [
    "- 의약품 RAG의 신뢰성을 확보하기 위해 “문서 근거 기반 답변”을 강제하도록 설계. \n",
    "- 답변은 반드시 제공된 [문서]에서 도출되며, 최소 1개~최대 2개의 직접 인용을 포함하도록 규칙을 부여해 근거 추적성을 높임. \n",
    "- 문서에 근거가 부족한 경우에만 “문서에 근거가 부족합니다”로 응답하도록 하여 추측/환각을 억제함. \n",
    "- 결론-이유-근거의 고정 포맷으로 출력을 제한하여 응답 일관성과 평가 용이성을 확보함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4f7a5",
   "metadata": {},
   "source": [
    "### 3.5 생성 모델 서빙 및 RAG Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527886c8",
   "metadata": {},
   "source": [
    "#### 3.5.1 목적\n",
    "- 벡터DB에서 검색된 문서를 컨텍스트로 주입해, LLM이 문서 근거 기반 답변을 생성하는 RAG Inference 모듈을 구현함\n",
    "- UI는 이 추론 모듈을 호출해 결과를 보여주는 레이어로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f47308",
   "metadata": {},
   "source": [
    "#### 3.5.2 구성 요소\n",
    "- Retriever: Chroma 기반 vectorstore.as_retriever(k=3)\n",
    "    - 약물명 확정 시: filter={\"drug_name\": chosen_drug_name} 적용\n",
    "- Context Formatter(format_docs)\n",
    "    - 검색된 문서를 문서1, 문서2, 문서3의 형식으로 정리\n",
    "    - drug_name/section/chunk_id 메타데이터를 함께 출력하여 근거 추적성 확보\n",
    "    - 문서 길이 상한(예: 1200자)을 두어 프롬프트 길이 안정화(truncation) 적용\n",
    "- Prompt Builder\n",
    "    - system_message.format(search_result=formatted_results)로 검색 결과를 system prompt에 주입\n",
    "    - tokenizer.apply_chat_template(messages, <br>\n",
    "        tokenize=False,<br>\n",
    "        add_generation_prompt = True,<br> \n",
    "        add_generation_prompt=True)로 모델 입력 프롬프트 생성\n",
    "- Generator(vLLM)\n",
    "    - vllm_model.generate([prompt], sampling_params)로 응답 생성\n",
    "    - 생성 결과 텍스트를 최종 답변으로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d84ef",
   "metadata": {},
   "source": [
    "#### 3.5.3 동작 흐름\n",
    "1. 사용자 질문 입력\n",
    "2. Retriever가 Top-k 문서 검색\n",
    "3. 검색 문서를 format_docs로 표준 포맷(문서번호+메타+본문)으로 변환\n",
    "4. 변환된 검색 결과를 system prompt에 삽입\n",
    "5. vLLM이 최종 답변 생성 및 반환\n",
    "6. 디버깅/검증을 위해 formatted_results, retrieved_docs도 함께 반환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2d2b7",
   "metadata": {},
   "source": [
    "#### 3.5.4 검색 결과 포맷\n",
    "- 각 문서는 다음의 헤더를 포함\n",
    "    - 문서{i} | drug_name | section | chunk_id\n",
    "- 이를 통해 모델 출력에 문제가 발생했을 때 “어떤 약물/섹션/청크가 근거로 들어갔는지”를 추적 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7140a6",
   "metadata": {},
   "source": [
    "#### 3.5.5 설계 의의\n",
    "- RAG 코어 모듈화: UI와 분리된 generate_rag_response()로 추론 파이프라인을 함수 단위로 고정하여 재사용성 확보\n",
    "- 입력 안정성: 문서 truncation과 표준 포맷을 통해 토큰 초과 및 컨텍스트 노이즈 축소\n",
    "- 정밀도 향상 여지: 약물명 필터(drug_name) 적용 시 검색 범위를 좁혀 혼선 가능성을 낮출 수 있도록 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1cd1ff",
   "metadata": {},
   "source": [
    "## phase 4. LLM 미세조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0cc1d3",
   "metadata": {},
   "source": [
    "[Fine-tuning-data code](https://github.com/eddy-fox/OTC-RAG-Pipeline-Llama3-Instruction-LoRA/blob/main/3.%20Fine-tuning-data%20code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f0590",
   "metadata": {},
   "source": [
    "### 4.1 학습 데이터 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48f4ce",
   "metadata": {},
   "source": [
    "- 데이터 생성 개요\n",
    "    - 학습 데이터는 약물 첨부문서 청크(df_chunk)를 기반으로 RAG 상황(검색 문서 다수 제공)을 가정하여 구성\n",
    "    - 각 샘플은 질문 1개 + 검색 문서 5개(정답 1 + hard negative 4) + 정답/무응답 라벨로 구성되며, 답변에는 인용 태그([[refN]])를 포함하도록 설계(근거 기반 학습 강화)\n",
    "\n",
    "1) 약물 단위 근거 문서 구성 및 샘플링\n",
    "    - drug_id 단위로 청크를 묶고, 컨텍스트를 “약물명 헤더 + 섹션 본문”으로 구성\n",
    "    - 컨텍스트 유형\n",
    "        - dosage: 용법용량 섹션을 가진 약물 중 500개 drug_id를 샘플링하여 용법용량 중심 context 생성\n",
    "        - warning: 나머지 약물은 주의사항 중심 context 생성\n",
    "    - 주의사항은 특정 sub_index 구간에 쏠리지 않도록 sub_index 범위를 균등 구간으로 나눠 고르게 warn_k개 추출\n",
    "    - 각 context에는 추적을 위해 source_chunk_ids 함께 저장\n",
    "    - 전체 context pack에서 총 1,000개를 튜닝 데이터로 선정\n",
    "    - 분포 편향을 줄이기 위해 컨텍스트 길이, 주의사항 총 청크수, 주성분 빈도를 고려한 층화(Stratified) 샘플링 적용\n",
    "    - dosage/warning 유형별로 다른 strata 조합을 적용해 길이·주의사항 규모·성분 다양성을 동시에 반영<br>\n",
    "2) 질문 생성\n",
    "    - gpt-4o-mini를 활용해 각 context에 대해 질문을 자동 생성\n",
    "    - 시스템 프롬프트 규칙 : 형식 일관성과 데이터 품질 확보\n",
    "        - CONTEXT 기반(추측 금지), 질문 1개\n",
    "        - 질문이 답을 암시하지 않음\n",
    "        - 질문은 반드시 약물명으로 시작하고 모호표현(“이 약/해당 약”) 금지\n",
    "        - JSON 1개만 반환하도록 제한 <br>\n",
    "3) Hard Negative 문서 구성\n",
    "    - context 임베딩을 미리 생성한 뒤 각 질문 임베딩과의 유사도 계산\n",
    "    - 정답 context를 제외하고 유사도가 높은 상위 4개를 선택해 negative_samples(4)로 구성\n",
    "    - 결과적으로 각 샘플은 정답 문서 1 + 유사한 오답 문서 4로 이루어진 multi-document 입력<br>\n",
    "4) general vs noanswer 분리\n",
    "    - SQuAD 2.0에서 unanswerable 질문을 포함해 ‘답변 가능/불가능 판별’ 능력을 학습시키는 설계를 참고하여 총 1,000개 샘플 중 약 30%를 no-answer로 구성.<sup>4)</sup>\n",
    "        - 출처 : <sup>4)</sup> [\"SQuAD\"](https://rajpurkar.github.io/SQuAD-explorer/)\n",
    "    - 분할 시 dosage/warning 비율을 유지하도록 샘플링 <br>\n",
    "5) general 답변 생성\n",
    "    - general 샘플에 대해 gpt-4o-mini로 답변을 생성\n",
    "    - 시스템 프롬프트 규칙 : \n",
    "        - 참고자료 표기 강제\n",
    "        - 검색결과에 없는 내용은 답을 찾을 수 없음으로 답변\n",
    "        - 사용자가 질문한 약물에 관한 문서를 찾아 답변\n",
    "    - 정규표현식으로 [[ref숫자]]를 추출하여 extracted_ref_numbers를 생성\n",
    "    - 인용이 전혀 없는 샘플(답변이 문서 근거 없이 생성되었거나 답변 불가)은 제거<br>\n",
    "6) No-answer 질문 생성\n",
    "    - gpi-4o-mini로 No-answer 질문 생성\n",
    "    - 시스템 프롬프트 규칙 :\n",
    "        - 각 문서와 연관은 있으나 5개 문서 전체로도 답변 불가능한 질문 5개를 생성\n",
    "    - 모델이 각 질문에 대해 True/False로 “정말 답변 불가능한지” 자기검증 후 True로 판정된 블록만 유지\n",
    "    - True 중 1개를 랜덤 선택하여 no_answer_question으로 확정<br>\n",
    "7) No-answer 답변 생성\n",
    "    - gpi-4o-mini로 No-answer 생성\n",
    "    - 확정된 no_answer_question에 대해 동일한 5개 문서를 제공\n",
    "    - 시스템 프롬프트 규칙 :\n",
    "        - 검색 결과에 답이 없을 경우 반드시 \"검색 결과에는 ~~을 찾을 수 없습니다.\" 형식으로 답변\n",
    "    - no_answer 답변에서도 [[refN]] 인용 태그를 추출하여 인용이 존재하는 샘플은 제거\n",
    "    - noanswer 라벨은 문서 근거로 답변 불가능이 핵심이므로 인용이 생긴 데이터는 라벨 오염(label noise)로 보고 제외\n",
    "8) 검색 결과(search_result) 구성\n",
    "    - general/noanswer 모두에서 RAG 입력을 일관되게 유지하기 위해, 정답 문서 1개와 hard negative 4개를 묶은 5개 문서를 search_result로 저장하여 multi-document 검색과 비슷하도록 환경 조성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11b60a",
   "metadata": {},
   "source": [
    "### 4.2 학습 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59513bb3",
   "metadata": {},
   "source": [
    "[Fine-tuning code](https://github.com/eddy-fox/OTC-RAG-Pipeline-Llama3-Instruction-LoRA/blob/main/4.%20Fine-tuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc77bd6",
   "metadata": {},
   "source": [
    "#### 4.2.1 학습 데이터 로딩 및 분할\n",
    "- 데이터의 type(general/noanswer) 분포를 유지하기 위해 type별 층화 방식으로 Train/Test를 분할(Train 80% / Test 20%)\n",
    "- search_result(문서 5개)를 문서1~문서5 형식으로 연결하여 system 메시지에 삽입\n",
    "- user에는 질문 / assistant에는 답변을 배치하는 chat-format(messages) 데이터로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc234855",
   "metadata": {},
   "source": [
    "#### 4.2.2 프롬프트(시스템 메시지) 구성\n",
    "\n",
    "- 검색 결과에 없는 내용 생성 금지\n",
    "- 답이 없으면 “검색 결과에는 ~에 대한 내용이 없습니다.” 형식으로 응답\n",
    "- 문서 인용 시 [[refN]] 형태로 출처 표기\n",
    "- 사용자가 질문한 약물에 해당하는 문서만 인용하도록 제한"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91a268",
   "metadata": {},
   "source": [
    "#### 4.2.3 베이스 모델 및 정밀도\n",
    "- 베이스 모델: 한국어 특화 오픈소스모델 NCSOFT/Llama-VARCO-8B-Instruct\n",
    "- 학습/추론 효율을 위해 BF16(bfloat16)로 로드 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07f460",
   "metadata": {},
   "source": [
    "#### 4.2.4 미세조정 방식(PEFT: LoRA)\n",
    "- 전체 파라미터 업데이트 비용을 줄이고, 제한된 데이터(1,000 샘플)에서도 안정적으로 학습하기 위해 LoRA 기반 PEFT를 적용\n",
    "- LoRA 설정:\n",
    "    - r=8\n",
    "    - lora_alpha=32\n",
    "    - lora_dropout=0.1\n",
    "    - target_modules=[\"q_proj\", \"v_proj\"]\n",
    "    - bias=\"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496583e2",
   "metadata": {},
   "source": [
    "#### 4.2.5 학습 하이퍼파라미터(SFTConfig)\n",
    "- 학습 프레임워크: trl의 SFTTrainer\n",
    "- 주요 설정:\n",
    "    - Epoch: 3\n",
    "    - Batch size: per_device_train_batch_size=2\n",
    "    - Gradient accumulation: 2 (유효 배치 크기 확장)\n",
    "    - Gradient checkpointing: True (메모리 절감)\n",
    "    - Optimizer: adamw_torch_fused\n",
    "    - Learning rate: 1e-4\n",
    "    - Warmup ratio: 0.03\n",
    "    - LR scheduler: constant\n",
    "    - Max grad norm: 0.3\n",
    "    - Logging: 10 step\n",
    "    - Save strategy: steps, save_steps=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12082415",
   "metadata": {},
   "source": [
    "#### 4.2.6 입력 길이 및 데이터 콜레이터(라벨 마스킹)\n",
    "- 최대 시퀀스 길이: 8192 tokens (max_seq_length=8192)\n",
    "    - system_message에 문서가 5개 포함되어있으므로 최대 시퀀스 길이를 모델의 최대 컨텍스트 길이로 설정\n",
    "- Llama-3 계열 채팅 템플릿 토큰을 사용해 프롬프트 구성\n",
    "    - <|begin_of_text|> + (system/user/assistant 메시지들을 <|start_header_id|>...<|eot_id|>로 연결)\n",
    "- 학습 라벨은 assistant 응답 구간만 loss에 반영\n",
    "    - system/user 구간: labels=-100\n",
    "    - assistant 응답(및 <|eot_id|>): label에 실제 토큰 id를 할당\n",
    "- 배치 단위로 padding을 수행하여 input_ids, attention_mask, labels 텐서를 생성하는 커스텀 collate_fn을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a0416",
   "metadata": {},
   "source": [
    "#### 4.2.7 학습 실행 및 저장\n",
    "- SFTTrainer 구성:\n",
    "    - train_dataset=train_dataset\n",
    "    - data_collator=collate_fn\n",
    "    - peft_config=LoRA\n",
    "    - max_seq_length=8192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca57857",
   "metadata": {},
   "source": [
    "### 4.3 평가 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21749c3",
   "metadata": {},
   "source": [
    "[모델 평가 code](https://github.com/eddy-fox/OTC-RAG-Pipeline-Llama3-Instruction-LoRA/blob/main/5.%20%EB%AA%A8%EB%8D%B8%20%ED%8F%89%EA%B0%80%20code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d9c96",
   "metadata": {},
   "source": [
    "#### 4.3.1 LLM-as-a-Judge 기반 RAG 품질 평가\n",
    "- RAG 시스템의 응답 품질을 사람 평가 대신 LLM 기반 평가자(gpt-4o-mini)를 사용하여 점수화하\n",
    "- 각 샘플에 대해 질문·검색된 컨텍스트·생성 답변·참조 정답을 함께 제공하고, 다음 4개 지표를 1~5점 척도로 평가하도록 프롬프트를 설계\n",
    "- 평가 지표(4종)\n",
    "    - 응답 정확성(Answer Correctness) : 생성 답변이 참조 정답과 비교해 정확/완전한지 평가\n",
    "    - 컨텍스트 관련성(Context Relevance) : 검색된 컨텍스트가 질문에 답하기에 충분히 관련 있는지 평가\n",
    "    - 컨텍스트 충실성(Context Faithfulness) : 답변이 컨텍스트에 기반했는지(환각 여부) 평가\n",
    "    - 컨텍스트 충분성(Context Recall) : 컨텍스트가 답을 구성하는 데 필요한 정보를 얼마나 포함하는지 평가\n",
    "- 4개 점수의 합을 총점(total_score, 4~20점)으로 산출하고, 평균 총점 및 지표별 평균을 계산하여 전반적 품질을 비교함\n",
    "- 결과\n",
    "\n",
    "|   | 튜닝 전 | 튜닝 후 |\n",
    "|--------|---------|----------|\n",
    "|평균 총점 | 17.94 | 18.71 |\n",
    "|응답 정확성 평균 | 4.57 | 4.85 |\n",
    "|컨텍스트 관련성 평균| 4.57 | 4.71 |\n",
    "|컨텍스트 충실성 평균| 4.78 | 4.99 | \n",
    "|컨텍스트 충분성 평균| 4.02 | 4.15 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed216c",
   "metadata": {},
   "source": [
    "#### 4.3.2 인용(ref) 기반 정량 평가\n",
    "- 생성 답변의 “근거 사용”을 정량적으로 평가하기 위해 정답과 예측 답변에 포함된 인용 태그 [[refN]]를 추출하여 문서 선택의 일치도를 측정함\n",
    "- 각 답변에서 정규표현식으로 ref 번호 목록을 추출한 뒤 정답의 ref 집합과 예측의 ref 집합의 교집합/차집합을 이용하여 Precision / Recall / F1을 계산\n",
    "- 이 평가는 답변 텍스트 자체가 아니라, 모델이 어떤 문서를 근거로 선택했는지를 평가한다는 점에서 LLM 점수(품질)와 상호보완적\n",
    "- 결과  \n",
    "    - 튜닝 전 \n",
    "        - f1 : 0.08510638297872342\n",
    "    - 튜닝 후\n",
    "        - f1 : 0.9847328244274809"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b30778",
   "metadata": {},
   "source": [
    "### 4.4 결과 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75177e0",
   "metadata": {},
   "source": [
    "LLM-as-a-Judge 평가(총 20점 만점)에서 평균 총점은 18.71점으로 전반적으로 높은 성능을 보였다. 세부 지표를 보면 컨텍스트 충실성(4.99/5)이 가장 높아, 모델이 검색 문서에 없는 내용을 임의로 생성하는 환각이 매우 낮고 근거 기반 응답 규칙이 안정적으로 학습되었음을 확인할 수 있다. 또한 응답 정확성(4.85/5)과 컨텍스트 관련성(4.71/5)도 높은 수준으로, 검색된 문서를 활용해 질문에 대해 대체로 정확하게 답변하고 있음을 보여준다. 반면 컨텍스트 충분성(4.15/5)은 상대적으로 낮게 나타났는데, 이는 일부 질문에서 검색 결과 자체가 답변에 필요한 정보를 완전히 포함하지 못했거나(리트리버 한계), 문서가 일부만 포함되어 답변이 부분적으로 제한되는 사례가 있었음을 확인할 수 있다.\n",
    "\n",
    "정량 평가로 수행한 인용(ref) 기반 F1은 0.985로 매우 높게 나타났다. 이는 모델이 답변 생성 시 정답과 동일한 문서(혹은 동일한 문서 집합)를 거의 정확히 선택해 인용하고 있음을 의미하며, “문서 근거 기반 답변 + 인용 태깅([[refN]])” 형식 학습이 성공적으로 이루어졌다고 볼 수 있다. 종합하면, 본 모델은 근거 충실성과 인용 일치도 측면에서 매우 강한 성능을 보였고, 향후 성능 개선은 주로 검색 단계의 컨텍스트 충분성(Recall) 향상(예: k 조정, 하이브리드 검색 강화, 재랭킹 도입 등)에 초점을 두는 것이 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f886c29",
   "metadata": {},
   "source": [
    "### 4.5 한계 및 개선 방향\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc052f",
   "metadata": {},
   "source": [
    "- 한계 1) 컨텍스트 충분성(Context Recall) 지표가 상대적으로 낮음\n",
    "    - LLM 평가에서 컨텍스트 충분성(4.15/5)이 다른 지표에 대비하여 낮게 나타났으며 이는 일부 질문에서 검색 결과가 답변에 필요한 정보를 충분히 포함하지 못한 경우가 존재함을 의미한다.\n",
    "    - 즉, 생성 모델의 환각은 낮지만(Faithfulness 4.99/5), 검색에 필요한 근거를 충분히 가져오지 못하는 경우가 있어 전체 성능이 제한될 수 있다.\n",
    "- 개선방향\n",
    "    - 질문 길이, 난이도에 따라 top-k 증가\n",
    "    - 약물명 키워드, 의미 검색 가중치 조정\n",
    "    - 선택된 문서를 질문에 더 잘 맞는 순서로 재정렬<br><br><br>\n",
    "\n",
    "- 한계 2) 약물명 후보 추출이 문자열 포함 매칭 기반이라 오탐, 누락 가능\n",
    "    - 현재 약물명 식별은 질문 토큰과 drug_name의 부분 문자열 매칭으로 후보를 만들기 때문에 유사한 상품명,표기 변형(띄어쓰기/괄호/용량)에서 오탐 또는 후보 누락이 발생하는 경우가 있다.\n",
    "- 개선방향\n",
    "    - 약물명 사전 정규화(괄호,용량,단위 제거/동의어 매핑)\n",
    "    - fuzzy matching, 형태소 기반 매칭 적용<br><br><br>\n",
    "\n",
    "- 한계 3) 컨텍스트 내 ‘근거 우선순위’ 선택 편향으로 답변이 과도하게 보수화되는 사례 존재\n",
    "    - 일부 질의에서 검색 컨텍스트가 질문 의도에 적합하게 연결되는 조항을 포함하고 있지만 생성 모델이 경고 강도가 높은 문장(경고/금기/간손상 등)을 우선적으로 선택하여 답변의 중심 근거로 사용하는 경향이 나타났다. 이 문제는 프롬프트를 여러 차례 변형하여 테스트한 이후에도 반복되어 프롬프트만으로 근거 우선순위 선택을 안정적으로 제어하기 어렵다는 한계가 확인되었다.\n",
    "- 개선방향\n",
    "    - LoRA 튜닝값 변경 시도 (r=16, alpha=4, o_proj 추가)\n",
    "    - 대분류 단위 청킹을 보완하여 문장 임베딩 유사도(주제 연속성)에 기반한 의미 단위 분할을 적용<br><br><br>\n",
    "\n",
    "- 한계 4) 효능·효과 섹션 미포함으로 증상에 맞는 약품에 대한 답변 범위 제한\n",
    "    - 복용방법(용법용량)과 주의사항 중심으로 문서를 구성하여 RAG 인덱싱을 수행했기 때문에 ‘생리통에 탁센 먹어도 돼?’ 와 같이 증상에 대한 질문이 입력될 경우 관련 근거 문서가 검색되지 않아 “문서에 근거가 부족합니다(알 수 없음)” 형태로 응답하는 한계가 나타난다. 현재 수집한 문서의 범위가 효능·효과 정보를 포함하지 않기 때문에 일어나는 문제로 확인된다. \n",
    "- 개선방향\n",
    "    - 초기 안내에 “현재는 주의사항·복용방법 중심”임을 표시하고 효능·효과 질문 시에는 근거 부족을 \"알 수 없음\"이 아니라 “효능·효과 정보 미포함” 사유로 설명\n",
    "    - 효능·효과 섹션을 추가 수집/청킹하여 인덱스 확장 (증상/적응증 질문에 대해 근거 기반 답변이 가능하도록 문서 범위를 확대)<br><br><br>\n",
    "\n",
    "- 한계 5) 2가지 이상 약물의 혼합 복용에 관한 질문에서 근거 활용 답변 제한\n",
    "    - 사용자는 보통 “타이레놀하고 탁센 같이 먹어도 돼?”처럼 약물명으로 질문하지만, 첨부문서의 병용 금기,주의 문구는 “다른 해열진통제”, “NSAIDs”, “아세트아미노펜 함유제”처럼 성분/계열 중심 표현으로 서술되는 경우가 많다. 현재 구조에서는 두 약물의 상품명을 성분으로 정규화하여 연결하는 단계가 없기 때문에 문서에 관련 경고가 존재하더라도 모델이 이를 직접 근거로 판단하지 못해 근거 부족 응답이 발생할 수 있다.\n",
    "- 개선방향 \n",
    "    - 이미 메타데이터에 존재하는 주성분명과 약물명을 매핑하여 각 약물의 성분과 계열 정보 주입\n",
    "    - 약물명이 2개 이상 존재하는 것이 확인되면 문서 내에 병용금지 부분에서 해당 약물들의 주성분과 연결하여 상품명을 성분, 계열로 바꾸어 같은 의미로 맞춰주는 단계 추가 \n",
    "\n",
    "- 총평\n",
    "    - 본 시스템은 문서 근거 기반 응답에서 충실성(Faithfulness 4.99/5)과 근거 인용 정합성(F1 0.985)이 매우 높아, 전반적으로 문서 밖 내용을 지어내지 않는 안정적인 RAG 응답을 구현하였다. 다만 컨텍스트 충분성(4.15/5)이 상대적으로 낮아 일부 질의에서 필요한 근거가 Top-k에 포함되지 못하는 경우가 있었고, 약물명 식별이 문자열 포함 매칭 기반이라 표기 변형(띄어쓰기,괄호,용량)에서 후보 오탐,누락이 발생할 가능성이 있다. 또한 동일 컨텍스트 내에서도 모델이 경고 강도가 높은 문장을 우선 선택해 답변이 과도하게 보수화되는 편향이 나타났으며 이는 프롬프트만으로 안정적으로 제어하기 어렵다는 한계가 확인되었다. 데이터 측면에서는 효능·효과를 포함하지 않아 증상에 알맞은 약물인지에 대한 질문에 근거 부족 응답이 발생했고 두 약물 병용 질문에서는 문서가 성분,계열 중심으로 서술되는 반면 사용자는 상품명으로 묻기 때문에 상품명-성분/계열 정규화가 존재하지 않아 근거를 충분히 활용하지 못할 수 있다.<br><br>\n",
    "\n",
    "    - 향후 개선은 (1) 질문 난이도에 따른 동적 Top-k 및 하이브리드 검색 가중치 조정, 검색 결과 재정렬로 리콜을 높이고, (2) 약물명 정규화·fuzzy/형태소 기반 매칭으로 엔티티 식별을 안정화하며, (3) LoRA 설정(r/alpha/target 모듈) 실험과 함께 의미 단위(문장 유사도 기반) 청킹으로 근거 선택 편향을 완화하는 방향이 효과적일 것이다. 또한 (4) 효능·효과 섹션을 추가 인덱싱하고, (5) 병용 질의에서는 메타데이터의 주성분 정보를 주입해 상품명을 성분,계열로 연결하는 매핑 단계를 도입하여 실제 사용자 질의 범위를 더 폭넓게 커버하는 서비스로 확장할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0013c",
   "metadata": {},
   "source": [
    "# E. 응용 및 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352c75b",
   "metadata": {},
   "source": [
    "[vllm 서빙 및 응용프로그램 code](https://github.com/eddy-fox/OTC-RAG-Pipeline-Llama3-Instruction-LoRA/blob/main/6.%20vLLM%20%EC%84%9C%EB%B9%99%20%EB%B0%8F%20%EC%9D%91%EC%9A%A9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8%20code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ba451",
   "metadata": {},
   "source": [
    "## phase 5. 응용 어플리케이션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5f2d4",
   "metadata": {},
   "source": [
    "### 5.1 서비스 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd1b9c",
   "metadata": {},
   "source": [
    "본 프로젝트는 일반의약품(OTC) 첨부문서 기반의 RAG 시스템을 사용자 친화적으로 제공하기 위해 Gradio 기반 챗봇 UI를 구현하였다. 사용자는 자연어로 질문을 입력하며, 시스템은 질문에서 약물명 후보를 탐색한 뒤 후보가 여러 개인 경우 번호 선택 방식으로 약물을 확정한다. 약물이 확정되면 해당 약물 메타데이터를 필터로 적용하여 검색 정확도를 높이고, 최종적으로 vLLM 기반 생성 모델이 검색 문서를 근거로 답변을 생성한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fe0cf",
   "metadata": {},
   "source": [
    "### 5.2 시스템 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6af10",
   "metadata": {},
   "source": [
    "- “UI → 후보 약물명 선택 → 필터 기반 검색 → RAG 응답 생성”의 단계로 구성\n",
    "    - UI 레이어(Gradio ChatInterface) : 사용자 질문 입력 및 후보 선택(번호 입력) 인터랙션 제공\n",
    "    - 약물명 후보 추출 모듈 : choose_best_token()을 통해 사용자 질의에서 토큰을 추출하고, 사전 구축된 drug_names 목록에서 부분 문자열 매칭으로 후보 약물명을 생성(최대 Top-10).\n",
    "    - Retriever(VectorDB 접근)\n",
    "        - 후보 선택 성공 시: filter={\"drug_name\": chosen}를 적용한 정밀 검색 수행\n",
    "        - 후보가 없을 시: 필터 없이 전체 검색 수행\n",
    "        - 공통적으로 검색 개수는 k=3으로 설정\n",
    "- Generator(vLLM 기반 RAG 생성)\n",
    "    - generate_rag_response()가 retriever 결과를 system prompt에 주입하고, vLLM으로 최종 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf3583",
   "metadata": {},
   "source": [
    "### 5.3 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e671f",
   "metadata": {},
   "source": [
    "#### 5.3.1 2-turn 후보 선택 UX(Disambiguation)\n",
    "- 약물명이 질문 내에 명확히 포함되지 않거나, 약물명 토큰이 여러 약물에 매칭되는 경우 오답 가능성이 높기 때문에 “질문 1턴 → 후보 선택 1턴”의 2-turn 흐름을 채택\n",
    "    - 1턴(질문 입력): get_candidates()에서 {token, cands}를 생성하고 후보가 존재하면 사용자에게 후보 목록 출력\n",
    "- 2턴(번호 입력): 사용자의 입력을 번호로 해석하여 후보 중 하나를 확정한 후 해당 약물로 필터 검색을 수행하여 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332baf8d",
   "metadata": {},
   "source": [
    "#### 5.3.2 상태 관리(gr.State)\n",
    "- Gradio의 gr.State(pending)을 사용해 “후보 선택 대기 상태”를 유지\n",
    "    - pending is None : 입력을 새 질문으로 처리하고 후보를 생성\n",
    "    - pending is not None : 입력을 번호 선택으로 처리하여 chosen 확정\n",
    "- 번호 입력이 잘못된 경우(ValueError)에는 상태를 유지한 채 “번호를 입력하라”는 안내를 반환하여 UX 안정화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0df991",
   "metadata": {},
   "source": [
    "#### 5.3.3 검색 분기 로직\n",
    "- 후보가 있을 때(선택 후)\n",
    "    - 동일 약물 문서만 검색하도록 제한해 검색 정밀도를 높임\n",
    "\n",
    "- 후보가 없을 때\n",
    "    - 약물명 매칭 실패 상황에서도 답변 가능성을 확보하기 위해 필터 없이 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e779f",
   "metadata": {},
   "source": [
    "### 5.4 운영 고려사항"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2abd77",
   "metadata": {},
   "source": [
    "- 응답 속도 및 검색 설정\n",
    "    - 검색 문서 수는 k=3으로 제한하여 응답 지연과 프롬프트 길이를 관리\n",
    "    - 후보 선택이 이루어진 경우 검색 공간이 크게 줄어 검색 정확도와 응답 속도 모두 개선되는 효과\n",
    "- 안전성(오답 방지)\n",
    "    - 약물명이 복수 후보로 잡힐 때 사용자 선택을 요구하여 다른 약물 문서를 근거로 답하는 오류를 구조적으로 축소\n",
    "    - 후보가 없을 때는 전체 검색으로 fallback하지만 이 경우는 오답 가능성이 상대적으로 높으므로 향후 개선 예정(약물명 정규화/NER 등)\n",
    "- 확장 방향\n",
    "    - 후보 선택을 항상 요구하는 대신 후보 1개만 존재하거나 신뢰도가 높은 경우 자동 선택(auto-pick) 옵션 추가 가능\n",
    "    - 질문 유형에 따라 주의사항/용법용량 등 섹션 기반 필터링을 추가 (검색 효율과 정확도 개선)\n",
    "    - 운영 단계에서는 질의/선택 로그를 수집해 오탐 토큰/누락 약물명을 개선 데이터로 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fa75",
   "metadata": {},
   "source": [
    "# F. 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abd9e3",
   "metadata": {},
   "source": [
    "RAG와 파인튜닝이 처음인 상태에서 데이터 수집부터 QA 데이터셋 제작, 청킹 설계, 모델 설정까지 전 과정을 혼자 근거를 찾아가며 진행하다 보니 여러번 작업을 되돌리고 다시 설계해야 했다. \n",
    "<br><br>\n",
    "초반에는 약물별 주의사항을 대분류 기준으로 3개씩 묶어 컨텍스트를 구성했지만, 이후 모델의 최대 컨텍스트 길이 제한에 부딪혔다. 이를 해결하기 위해 긴 컨텍스트는 근거 문서만 남기거나 길이 기준으로 절단하는 방법을 시도했지만 문맥 손실이 크게 발생해서 F1 score가 0.2 수준까지 하락했고 결국 대분류를 한 단위씩 다시 청킹하며 데이터 구조를 재정비하는 과정부터 다시 시작해야 했다.\n",
    "<br><br>\n",
    "학습 데이터 생성 단계에서는 처음에 Llama-VARCO-8B 기반으로 전 과정을 처리하려고 했지만 생성 시간이 예상보다 과도하게 길어졌다. 이후 모델 특성과 비용,성능을 다시 검토한 뒤 QA 생성 모델을 gpt-4o-mini로 최종 결정하면서 데이터 생성 시간이 크게 단축되었고 이전보다 더 품질이 좋은 데이터를 생성할 수 있었다.\n",
    "<br><br>\n",
    "이번 경험을 통해 프로젝트 성능은 모델 자체뿐 아니라 데이터 가공과 모델 선택 등의 초기 의사결정에 크게 좌우된다는 점을 확인했다. 결론적으로 모델별 특성 차이와 적절한 청크/컨텍스트 길이를 사전에 충분히 조사하고 시작했다면 시행착오를 줄이고 더 효율적으로 진행할 수 있었을 것이라는 아쉬움이 남는다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
